from langchain_community.embeddings import HuggingFaceEmbeddings
import torch


def embeddings():
    # Define the path to the pre-trained model you want to use
    modelPath = "sentence-transformers/all-MiniLM-l6-v2"

    # Create a dictionary with model configuration options, specifying to use the CPU for computations
    model_kwargs = {'device':'cuda' if torch.cuda.is_available() else 'cpu'}

    # Create a dictionary with encoding options, specifically setting 'normalize_embeddings' to False
    encode_kwargs = {'normalize_embeddings': False}

    # Initialize an instance of HuggingFaceEmbeddings with the specified parameters
    embeddings = HuggingFaceEmbeddings(
        model_name=modelPath,    
        model_kwargs=model_kwargs, 
        encode_kwargs=encode_kwargs 
)
    return embeddings
